---
version: '3'

tasks:
  build:ubuntu:
    desc: Build Ubuntu Nomad template
    cmds:
      - |
        fish -c "source scripts/set-proxmox-password.fish && packer build -var-file=packer/variables/common.pkrvars.hcl -var-file=packer/variables/proxmox-host1.pkrvars.hcl packer/templates/ubuntu/ubuntu-nomad.pkr.hcl"

  # build:alpine:
  #   desc: Build Alpine Nomad template
  #   cmds:
  #     - |
  #       bash -lc "PKR_VAR_clone_vm_id=\${PKR_VAR_clone_vm_id:-9001} PACKER_LOG=1 PKR_VAR_ssh_username=\${PKR_VAR_ssh_username:-\"$ALPINE_SSH_USERNAME\"} packer build packer/templates/alpine/alpine.pkr.hcl"

  build:base:
    desc: Build Ubuntu base image
    cmds:
      - |
        fish -c "source scripts/set-proxmox-password.fish && packer build -var-file=packer/variables/common.pkrvars.hcl -var-file=packer/variables/proxmox-host1.pkrvars.hcl packer/templates/ubuntu/ubuntu-bare-minimum.pkr.hcl"

  build:minimal:
    desc: Build minimal Ubuntu cloud agent template (qga + cloud-init)
    cmds:
      - |
        fish -c "source scripts/set-proxmox-password.fish && packer build -var-file=packer/variables/common.pkrvars.hcl -var-file=packer/variables/proxmox-host1.pkrvars.hcl packer/templates/ubuntu/ubuntu-qemu-agent.pkr.hcl"

  build:debian:base:
    desc: Create Debian 12 Cloud Base Template (VM 9400)
    cmds:
      - bash packer/scripts/create-debian-cloud-base.sh 10.0.0.21

  build:debian:client:
    desc: Build Debian Nomad Client template
    cmds:
      - |
        fish -c "source scripts/set-proxmox-password.fish && packer build -var-file=packer/variables/common.pkrvars.hcl -var-file=packer/variables/proxmox-host1.pkrvars.hcl packer/templates/debian/debian-nomad-client.pkr.hcl"

  build:debian:server:
    desc: Build Debian Nomad Server template
    cmds:
      - |
        fish -c "source scripts/set-proxmox-password.fish && packer build -var-file=packer/variables/common.pkrvars.hcl -var-file=packer/variables/proxmox-host1.pkrvars.hcl packer/templates/debian/debian-nomad-server.pkr.hcl"

  validate:
    desc: Validate all Packer templates
    cmds:
      - packer validate packer/templates/ubuntu/ubuntu-nomad.pkr.hcl
      # - packer validate packer/templates/alpine/alpine.pkr.hcl
      - packer validate packer/templates/ubuntu/ubuntu-bare-minimum.pkr.hcl
      - packer validate packer/templates/debian/debian-nomad-client.pkr.hcl
      - packer validate packer/templates/debian/debian-nomad-server.pkr.hcl

  fmt:
    desc: Format all Packer templates
    cmds:
      - packer fmt -recursive packer/templates/

  tf:init:
    desc: "Initialize Terraform workspace"
    cmds:
      - |
        cd terraform/environments/dev && terraform init

  tf:plan:
    desc: "Terraform plan"
    cmds:
      - |
        cd terraform/environments/dev && terraform plan

  tf:apply:
    desc: "Terraform apply (will create VMs)"
    cmds:
      - |
        cd terraform/environments/dev && terraform init && terraform apply -auto-approve

  tf:destroy:
    desc: "Terraform destroy (will tear down VMs created by Terraform)"
    cmds:
      - |
        cd terraform/environments/dev && terraform init && terraform destroy -auto-approve

  setup:volumes:
    desc: "Create required host volumes on Nomad clients (NAS-based)"
    cmds:
      - |
        echo "Volumes are auto-created on NAS during VM provisioning"
        echo "Verifying NAS mount on clients..."
        ssh ubuntu@10.0.0.60 "df -h /mnt/nas && ls -la /mnt/nas/"
      - |
        ssh ubuntu@10.0.0.61 "df -h /mnt/nas && ls -la /mnt/nas/"
      - echo "NAS storage verified on both clients"

  ansible:configure:
    desc: "Configure all nodes with Ansible (Docker, Nomad, base system)"
    cmds:
      - |
        cd ansible && ansible-playbook playbooks/site.yml

  ansible:docker:
    desc: "Configure Docker registry mirror on clients only"
    cmds:
      - |
        cd ansible && ansible-playbook playbooks/configure-docker.yml

  ansible:test:
    desc: "Test Ansible connectivity to all nodes"
    cmds:
      - |
        cd ansible && ansible-playbook playbooks/test-connectivity.yml

  tailscale:deploy:
    desc: "Deploy Tailscale on Nomad clients for remote access"
    cmds:
      - |
        cd ansible && ansible-playbook playbooks/deploy-tailscale.yml

  tailscale:deploy:traefik:
    desc: "Deploy Tailscale only on the Traefik node (nomad-client-1)"
    cmds:
      - |
        cd ansible && ansible-playbook playbooks/deploy-tailscale.yml --limit nomad-client-1

  tailscale:status:
    desc: "Check Tailscale status on all clients"
    cmds:
      - |
        cd ansible && ansible nomad_clients -m command -a "tailscale status" -b

  tailscale:ip:
    desc: "Get Tailscale IPs for all clients"
    cmds:
      - |
        cd ansible && ansible nomad_clients -m command -a "tailscale ip -4" -b

  deploy:system:
    desc: "Deploy system jobs (Traefik, Alloy)"
    cmds:
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/system/traefik.nomad.hcl
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/system/alloy.nomad.hcl

  deploy:services:
    desc: "Deploy service jobs (monitoring stack, registry, apps)"
    cmds:
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/services/observability/loki/loki.nomad.hcl
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/services/infrastructure/minio/minio.nomad.hcl
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/services/observability/prometheus/prometheus.nomad.hcl
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/services/observability/grafana/grafana.nomad.hcl
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/services/development/docker-registry/docker-registry.nomad.hcl
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/services/infrastructure/whoami/whoami.nomad.hcl
      - echo "All service jobs deployed successfully"

  deploy:speedtest:
    desc: "Deploy Speedtest Tracker"
    cmds:
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/services/infrastructure/speedtest/speedtest.nomad.hcl

  deploy:immich:
    desc: "Deploy Immich photo backup service"
    cmds:
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/services/media/immich/immich.nomad.hcl

  homepage:sync:
    desc: "üè† Sync homepage configuration files to NAS"
    cmds:
      - |
        echo "üì§ Syncing homepage configs to /mnt/nas/homepage/..."
        cd ansible && ansible-playbook playbooks/sync-homepage-config.yml
        echo "‚úÖ Homepage configs synced"

  homepage:deploy:
    desc: "üè† Deploy homepage service"
    cmds:
      - |
        echo "üöÄ Deploying homepage..."
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/services/infrastructure/homepage/homepage.nomad.hcl
        echo "‚úÖ Homepage deployed"

  homepage:update:
    desc: "üè† Sync configs and redeploy homepage (quick update workflow)"
    cmds:
      - task: homepage:sync
      - task: homepage:deploy

  db:migrate:
    desc: "üóÑÔ∏è  Migrate services from SQLite/embedded DB to central PostgreSQL"
    cmds:
      - |
        fish scripts/migrate-databases.fish

  deploy:all:
    desc: "Deploy all Nomad jobs in correct order"
    cmds:
      - task: deploy:system
      - task: deploy:services

  bootstrap:check:
    desc: "Validate bootstrap prerequisites without executing"
    cmds:
      - |
        echo "üîç Validating bootstrap prerequisites..."
        echo ""
      - |
        echo "‚úì Checking Proxmox templates..."
        ssh root@10.0.0.21 "qm list | grep -E '(9500|9501)'" && echo "  Templates found: 9500 (server), 9501 (client)" || (echo "  ‚ùå ERROR: Required templates not found" && exit 1)
      - |
        echo "‚úì Checking Terraform configuration..."
        cd terraform/environments/dev && terraform validate && echo "  Terraform config valid"
      - |
        echo "‚úì Checking Ansible connectivity..."
        cd ansible && ansible all -m ping -o | head -10 || echo "  ‚ö†Ô∏è  Some nodes may be unreachable (expected if VMs not yet provisioned)"
      - |
        echo ""
        echo "‚úÖ Prerequisites validated!"
        echo "Run 'task bootstrap' to execute full deployment"

  bootstrap:
    desc: "üöÄ Complete infrastructure bootstrap from scratch"
    cmds:
      - |
        echo "==== Step 1/5: Building Packer templates ===="
        echo "Note: Requires Proxmox host to have DNS configured"
        echo "Skipping base template - using existing templates 9500/9501"
      - |
        echo "Verifying templates exist..."
      - |
        ssh root@10.0.0.21 "qm list | grep -E '(9500|9501)'" || (echo "ERROR: Required templates not found. Run 'task build:debian:server' and 'task build:debian:client' first." && exit 1)
      - |
        echo "==== Step 2/5: Provisioning VMs with Terraform ===="
      - task: tf:apply
      - |
        echo "==== Step 3/5: Waiting for VMs to boot (60s) ===="
        sleep 60
      - |
        echo "==== Step 4/5: Configuring nodes with Ansible ===="
      - task: ansible:configure
      - |
        echo "==== Step 5/5: Deploying Nomad jobs ===="
      - task: deploy:all
      - |
        echo ""
        echo "‚úÖ Bootstrap complete! Access services at:"
        echo "   - Nomad UI:       http://10.0.0.50:4646"
        echo "   - Consul UI:      http://10.0.0.50:8500"
        echo "   - Grafana:        http://grafana.home"
        echo "   - Prometheus:     http://prometheus.home"
        echo "   - Registry UI:    http://registry-ui.home"
        echo "   - Traefik:        http://traefik.home"

  # ======================================
  # Vault Hub Cluster Tasks
  # ======================================
  
  vault:tf:init:
    desc: "Initialize Terraform for Vault hub cluster"
    cmds:
      - |
        cd terraform/environments/hub && terraform init

  vault:tf:plan:
    desc: "Plan Vault hub cluster infrastructure"
    cmds:
      - |
        cd terraform/environments/hub && terraform plan

  vault:tf:apply:
    desc: "Deploy Vault hub cluster VMs (3 nodes at 10.0.0.30-32)"
    cmds:
      - |
        cd terraform/environments/hub && terraform init && terraform apply -auto-approve

  vault:tf:destroy:
    desc: "Destroy Vault hub cluster infrastructure"
    cmds:
      - |
        cd terraform/environments/hub && terraform destroy -auto-approve

  vault:deploy:consul:
    desc: "Deploy Consul on hub Vault cluster for service discovery"
    cmds:
      - |
        cd ansible && ansible-playbook -i inventory/hub.yml playbooks/deploy-hub-consul.yml

  vault:deploy:vault:
    desc: "Deploy Vault HA cluster on hub nodes"
    cmds:
      - |
        cd ansible && ansible-playbook -i inventory/hub.yml playbooks/deploy-hub-vault.yml

  vault:unseal:
    desc: "Unseal Vault cluster nodes (requires credentials)"
    cmds:
      - |
        echo "‚ö†Ô∏è  Make sure you have sourced credentials first:"
        echo "   source ansible/.vault-hub-credentials"
        echo ""
        cd ansible && ansible-playbook -i inventory/hub.yml playbooks/unseal-vault.yml

  vault:deploy:full:
    desc: "üîê Complete Vault hub cluster deployment"
    cmds:
      - |
        echo "==== Step 1/4: Deploying Vault cluster VMs ===="
      - task: vault:tf:apply
      - |
        echo ""
        echo "==== Step 2/4: Waiting for VMs to boot (60s) ===="
        sleep 60
      - |
        echo ""
        echo "==== Step 3/4: Deploying Consul for service discovery ===="
      - task: vault:deploy:consul
      - |
        echo ""
        echo "==== Step 4/4: Deploying Vault HA cluster ===="
      - task: vault:deploy:vault
      - |
        echo ""
        echo "‚úÖ Vault hub cluster deployed!"
        echo ""
        echo "üìã Next steps:"
        echo "   1. Save credentials from ansible/.vault-hub-credentials"
        echo "   2. Source credentials: source ansible/.vault-hub-credentials"
        echo "   3. Check status: vault status"
        echo "   4. Access UI: http://10.0.0.30:8200"
        echo ""
        echo "‚ö†Ô∏è  IMPORTANT: Back up your unseal keys and root token!"

  vault:status:
    desc: "Check Vault cluster status (all nodes)"
    cmds:
      - |
        for i in 30 31 32; do
          echo "=== Vault Node 10.0.0.$i ==="
          VAULT_ADDR=http://10.0.0.$i:8200 vault status || echo "  ‚ùå Not accessible"
          echo ""
        done

  vault:test:
    desc: "Test Vault cluster - write and read a secret"
    cmds:
      - |
        echo "Testing Vault cluster functionality..."
        export VAULT_ADDR=http://10.0.0.30:8200
        echo ""
        echo "1. Enabling KV secrets engine..."
        vault secrets enable -path=test kv-v2 || echo "  Already enabled"
        echo ""
        echo "2. Writing test secret..."
        vault kv put test/hello foo=world created_by=taskfile
        echo ""
        echo "3. Reading test secret..."
        vault kv get test/hello
        echo ""
        echo "4. Deleting test secret..."
        vault kv delete test/hello
        echo ""
        echo "‚úÖ Vault cluster test complete!"

  # ======================================
  # MCP Server Tasks
  # ======================================
  
  mcp:build:all:
    desc: "Build all MCP servers"
    cmds:
      - task: mcp:build:nomad
      - task: mcp:build:consul
      - task: mcp:build:vault
      - task: mcp:build:terraform
      - task: mcp:build:ansible
      - task: mcp:build:proxmox
      - task: mcp:build:traefik
      - task: mcp:build:prometheus

  mcp:build:nomad:
    desc: "Build Nomad MCP server"
    cmds:
      - |
        cd mcp-servers/nomad && npm install && npm run build

  mcp:build:consul:
    desc: "Build Consul MCP server"
    cmds:
      - |
        cd mcp-servers/consul && npm install && npm run build

  mcp:build:vault:
    desc: "Build Vault MCP server"
    cmds:
      - |
        cd mcp-servers/vault && npm install && npm run build

  mcp:build:terraform:
    desc: "Build Terraform MCP server"
    cmds:
      - |
        cd mcp-servers/terraform && npm install && npm run build

  mcp:build:ansible:
    desc: "Build Ansible MCP server"
    cmds:
      - |
        cd mcp-servers/ansible && npm install && npm run build

  mcp:build:proxmox:
    desc: "Build Proxmox MCP server"
    cmds:
      - |
        cd mcp-servers/proxmox && npm install && npm run build

  mcp:build:traefik:
    desc: "Build Traefik MCP server"
    cmds:
      - |
        cd mcp-servers/traefik && npm install && npm run build

  mcp:build:prometheus:
    desc: "Build Prometheus MCP server"
    cmds:
      - |
        cd mcp-servers/prometheus && npm install && npm run build

  mcp:dev:nomad:
    desc: "Run Nomad MCP server in dev mode"
    cmds:
      - |
        cd mcp-servers/nomad && npm run dev

  mcp:test:nomad:
    desc: "Test Nomad MCP server with inspector"
    cmds:
      - |
        cd mcp-servers/nomad && npx @modelcontextprotocol/inspector node dist/index.js

  deploy:
    desc: "Deploy all Nomad jobs in correct order"
    cmds:
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/system/traefik.nomad.hcl
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/services/infrastructure/minio/minio.nomad.hcl
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/services/observability/prometheus/prometheus.nomad.hcl
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/services/observability/grafana/grafana.nomad.hcl
      - |
        NOMAD_ADDR=http://10.0.0.50:4646 nomad job run jobs/services/infrastructure/whoami/whoami.nomad.hcl
      - echo "All jobs deployed successfully"
